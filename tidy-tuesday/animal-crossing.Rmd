---
title: "Animal Crossing"
author: "Thinh"
date: "9/12/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Prerequisites
There are 3 datasets: 
* Critics 
* User Reviews 
* Items 

```{r}
library(tidyverse)
library(tidytext) # for text mining
library(lubridate) 
theme_set(theme_light())

critic <- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/critic.tsv')
user_reviews <- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/user_reviews.tsv')
items <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/items.csv')
villagers <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv')
```

For this analysis, I choose the `user reviews` for doing some text mining and analysis 

# Text analysis

Let's split the text into words and take out irrelevant words
```{r}
user_review_words <- user_reviews %>% 
  unnest_tokens(word, text) %>% 
  anti_join(stop_words, by = "word") %>% 
  count(user_name, date, grade, word)
```

## EDA 

Take a look on the distribution of some variables


### Grades
```{r}
user_reviews %>% 
  ggplot(aes(grade)) +
  geom_histogram() + 
  labs(title = "The distribution of grades",
       x = "Grade", 
       y= "Count")
```

Get a feel with what people say about Animal Crossing. 
```{r}
user_reviews %>% 
  filter(grade > 8) %>% 
  sample_n(5) %>% 
  pull(text)
```

### Average grade over the time 
```{r}
by_week <- user_reviews %>% 
  group_by(week = floor_date(date, "week", week_start = 1)) %>% 
  summarise(nb_reviews = n(),
            avg_grade = mean(grade),
            pct_zero = mean(grade == 0),
            pct_ten = mean(grade == 10))
  
  
  
by_week %>% 
  filter(nb_reviews >= 20) %>% 
  ggplot(aes(week, avg_grade)) +
  geom_line() + 
  geom_point(aes(size = nb_reviews)) +
  expand_limits(y = 0) + 
  labs(
    x = "Time",
    y = "Average grade",
    size = "# reviews"
  )
```

Break down into good, bad rating

```{r}
by_week %>% 
  pivot_longer(starts_with("pct"), 
                names_to = "type") %>% 
  mutate(type = ifelse(type == "pct_zero", "% 0 grade", "% 10 grade")) %>% 
  ggplot(aes(week, value, colour = type)) +
  geom_line() + 
  geom_point(aes(size=nb_reviews)) + 
  geom_vline(xintercept = c(date("2020-04-01"), date("2020-04-12")), lty = 2) + 
  expand_limits(y = 0) + 
  scale_y_continuous(label = scales::percent) + 
  labs(
    x = "Time", 
    y = "% of reviews",
    size = "# reviews in a week"
  )
```

### Number of words per review
```{r}
user_review_words %>% 
  distinct(user_name, word) %>% 
  count(user_name) %>%  
  ggplot(aes(n)) + 
  geom_histogram() + 
  labs(
    title = "The distribution of # words per review", 
    x = "# words",
    y = "Frequency"
  ) + 
  scale_x_log10()
```
It looks like normal distribution which is great.


```{r}
by_word <- user_review_words %>% 
  group_by(word) %>% 
  summarise(avg_grade = mean(grade), 
            nb_reviews = n()) %>% 
  arrange(desc(nb_reviews)) %>% 
  filter(nb_reviews>= 75) %>% 
  arrange(desc(avg_grade)) 

by_word %>% 
  ggplot(aes(nb_reviews, avg_grade)) + 
  geom_point() +
  geom_text(aes(label = word), vjust = 1, hjust = 1, check_overlap = TRUE) + 
  scale_x_log10()

```


```{r}
by_word %>% 
  top_n(20, -avg_grade) %>% 
  ggplot(aes(nb_reviews, avg_grade)) + 
  geom_point() + 
  geom_text(aes(label = word), hjust = 1, vjust = 1, check_overlap = TRUE) + 
  scale_x_log10() + 
  labs(title = "What words are associated with low-grade review",
       subtitle = "20 most negative; only words are at least 75 reviews")
```

```{r}
reviews_parsed <- user_reviews %>% 
  mutate(rating = ifelse(grade > 7, "good", "bad"),
         text = str_remove(text, "Expand$"))
```

```{r}
library(widyr)
library(stm)

review_matrix <- user_review_words %>% 
  group_by(word) %>% 
  filter(n() >= 25) %>% 
  cast_sparse(user_name, word, n)

topic_model <- stm(review_matrix, 
                   K = 4, 
                   verbose = FALSE, init.type = "Spectral")
```

```{r}
tidy(topic_model) %>% 
  group_by(topic) %>% 
  top_n(12, beta) %>%
  mutate(term = reorder_within(term, beta, topic)) %>% 
  ggplot(aes(beta, term)) + 
  geom_col() + 
  scale_y_reordered() + 
  facet_wrap(~ topic, scales = "free_y")
```


```{r}
topic_model_6 <- stm(review_matrix, 
                   K = 6, 
                   verbose = FALSE, init.type = "Spectral",
                   emtol = 5e-5)
```

```{r}
tidy(topic_model_6) %>% 
  group_by(topic) %>% 
  top_n(12, beta) %>%
  mutate(term = reorder_within(term, beta, topic)) %>% 
  ggplot(aes(beta, term)) + 
  geom_col() + 
  scale_y_reordered() + 
  facet_wrap(~ topic, scales = "free_y")
```

```{r}
topic_model_gamma <- tidy(topic_model_6, matrix = "gamma") %>% 
  mutate(user_name = rownames(review_matrix)[document])

topic_model_gamma %>% 
  group_by(topic) %>% 
  top_n(1, gamma) %>% 
  inner_join(user_reviews, by="user_name")
```


## Build a model
```{r}
library(tidymodels)

set.seed(123)
review_split <- initial_split(reviews_parsed, stata = rating)
review_train <- training(review_split)
review_test <- testing(review_split)
```


```{r}
library(textrecipes)

review_rec <- recipe(rating ~ text, data = review_train) %>% 
  step_tokenize(text) %>% 
  step_stopwords(text) %>% 
  step_tokenfilter(text, max_tokens = 500) %>% 
  step_tfidf(text) %>% 
  step_normalize(all_predictors())
```

```{r}
lasso_spec <- logistic_reg(penalty = tune(), mixture = 1) %>% 
  set_engine("glmnet")

lasso_wf <- workflow() %>% 
  add_recipe(review_rec) %>% 
  add_model(lasso_spec)

lasso_wf
```

## Tune model parameters

```{r}
lambda_grid <- grid_regular(penalty(), levels = 30)

set.seed(123)
review_folds <- bootstraps(review_train, strata = rating)
review_folds
```


```{r}
doParallel::registerDoParallel()

set.seed(2020)
lasso_grid <- tune_grid(
  lasso_wf,
  resamples = review_folds,
  grid = lambda_grid,
  metrics = metric_set(roc_auc, ppv, npv)
)
```

```{r}
lasso_grid %>% 
  collect_metrics() %>% 
  ggplot(aes(penalty, mean, color = .metric)) + 
  geom_line(size = 1.5, show.legend = FALSE) + 
  facet_wrap(~ .metric) + 
  scale_x_log10()
```

## Chose the final model 

```{r}
best_auc <- lasso_grid %>% 
  select_best("roc_auc")

best_auc

final_lasso <- finalize_workflow(lasso_wf, best_auc)

final_lasso
```

```{r}
library(vip)

final_lasso %>% 
  fit(review_train) %>% 
  pull_workflow_fit() %>% 
  vi(lambda = best_auc$penalty) %>% 
  group_by(Sign) %>% 
  top_n(20, wt = abs(Importance)) %>% 
  ungroup() %>% 
  mutate(Importance = abs(Importance),
         Variable = str_remove_all(Variable, "tfidf_text_"),
         Variable = fct_reorder(Variable, Importance)) %>% 
  ggplot(aes(x = Importance, y = Variable, fill = Sign)) + 
  geom_col() + 
  facet_wrap(~ Sign, scales = "free_y") + 
  theme(legend.position = "none")
```


```{r}
review_final <- last_fit(final_lasso, review_split)

review_final %>% 
  collect_metrics()

review_final %>% 
  collect_predictions() %>% 
  conf_mat(rating, .pred_class)
```

